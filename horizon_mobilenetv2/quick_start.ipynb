{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 快速入门\n",
    "\n",
    "用户可以从[这里](quick_start.ipynb.tar)下载本文示例脚本。\n",
    "\n",
    "## 基本流程\n",
    "\n",
    "量化训练工具的基本使用流程如下：\n",
    "\n",
    "![](quick_start.svg)\n",
    "\n",
    "下面以 `torchvision` 中的 `MobileNetV2` 模型为例，介绍流程中每个阶段的具体操作。\n",
    "\n",
    "出于流程展示的执行速度考虑，我们使用了 cifar-10 数据集，而不是 ImageNet-1K 数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 必要的 import，此段代码在文档编译结果中隐藏\n",
    "\n",
    "# 不显示警告\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.quantization\n",
    "import torchvision.transforms as transforms\n",
    "from torch import Tensor\n",
    "from torch.quantization import DeQuantStub\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models.mobilenetv2 import MobileNetV2\n",
    "from torch.utils import data\n",
    "from horizon_plugin_pytorch.march import March, set_march\n",
    "from horizon_plugin_pytorch.quantization import (\n",
    "    QuantStub,\n",
    "    convert_fx,\n",
    "    prepare_qat_fx,\n",
    "    set_fake_quantize,\n",
    "    FakeQuantState,\n",
    "    check_model,\n",
    "    compile_model,\n",
    "    perf_model,\n",
    "    visualize_model,\n",
    ")\n",
    "from horizon_plugin_pytorch.functional import rgb2centered_yuv\n",
    "from horizon_plugin_pytorch.quantization.qconfig import (\n",
    "    default_calib_8bit_fake_quant_qconfig,\n",
    "    default_qat_8bit_fake_quant_qconfig,\n",
    "    default_qat_out_8bit_fake_quant_qconfig,\n",
    "    default_calib_out_8bit_fake_quant_qconfig,\n",
    ")\n",
    "from typing import Optional, Callable, List, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "# 必要的 helper_function，此段代码在文档编译结果中隐藏\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name: str, fmt=\":f\"):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "def accuracy(output: Tensor, target: Tensor, topk=(1,)) -> List[Tensor]:\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified\n",
    "    values of k\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].float().sum()\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module, data_loader: data.DataLoader, device: torch.device\n",
    ") -> Tuple[AverageMeter, AverageMeter]:\n",
    "    top1 = AverageMeter(\"Acc@1\", \":6.2f\")\n",
    "    top5 = AverageMeter(\"Acc@5\", \":6.2f\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, target in data_loader:\n",
    "            image, target = image.to(device), target.to(device)\n",
    "            output = model(image)\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            top1.update(acc1, image.size(0))\n",
    "            top5.update(acc5, image.size(0))\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "        print()\n",
    "\n",
    "    return top1, top5\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    criterion: Callable,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: Optional[torch.optim.lr_scheduler._LRScheduler],\n",
    "    data_loader: data.DataLoader,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "    top1 = AverageMeter(\"Acc@1\", \":6.3f\")\n",
    "    top5 = AverageMeter(\"Acc@5\", \":6.3f\")\n",
    "    avgloss = AverageMeter(\"Loss\", \":1.5f\")\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for image, target in data_loader:\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        top1.update(acc1, image.size(0))\n",
    "        top5.update(acc5, image.size(0))\n",
    "        avgloss.update(loss, image.size(0))\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "    print()\n",
    "\n",
    "    print(\n",
    "        \"Full cifar-10 train set: Loss {:.3f} Acc@1\"\n",
    "        \" {:.3f} Acc@5 {:.3f}\".format(avgloss.avg, top1.avg, top5.avg)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取浮点模型\n",
    "\n",
    "首先，对浮点模型做必要的改造，以支持量化相关操作。模型改造必要的操作有：\n",
    "\n",
    "- 在模型输入前插入 `QuantStub`\n",
    "- 在模型输出后插入 `DequantStub`\n",
    "\n",
    "改造模型时需要注意：\n",
    "\n",
    "- 插入的 `QuantStub` 和 `DequantStub` 必须注册为模型的子模块，否则将无法正确处理它们的量化状态\n",
    "- 多个输入仅在 scale 相同时可以共享 `QuantStub`，否则请为每个输入定义单独的 `QuantStub`\n",
    "- 若需要将上板时输入的数据来源指定为 `\"pyramid\"`，请手动设置对应 `QuantStub` 的 `scale` 参数为 `1/128`\n",
    "- 也可以使用 `torch.quantization.QuantStub`，但是仅有 `horizon_plugin_pytorch.quantization.QuantStub` 支持通过参数手动固定 scale\n",
    "\n",
    "改造后的模型可以无缝加载改造前模型的参数，因此若已有训练好的浮点模型，直接加载即可，否则需要正常进行浮点训练。\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**注意**\n",
    "\n",
    "模型上板时的输入图像数据一般为 centered_yuv444 格式，因此模型训练时需要把图像转换成 centered_yuv444 格式（注意下面代码中对 `rgb2centered_yuv` 的使用）。\n",
    "\n",
    "如果无法转换成 centered_yuv444 格式进行模型训练，请参考[RGB888 数据部署](../advanced_content/rgb888_deploy.md)章节中的介绍，对模型做相应的改造。（注意，该方法可能导致模型精度降低）\n",
    "\n",
    "本示例中浮点和 QAT 训练的 epoch 较少，仅为说明训练工具使用流程，精度不代表模型最好水平。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 2.168 Acc@1 18.366 Acc@5 67.776\n",
      "........................................\n",
      "Float Epoch 0: evaluation Acc@1 31.690 Acc@5 84.770\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.837 Acc@1 31.224 Acc@5 83.192\n",
      "........................................\n",
      "Float Epoch 1: evaluation Acc@1 39.800 Acc@5 89.690\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.682 Acc@1 37.486 Acc@5 87.344\n",
      "........................................\n",
      "Float Epoch 2: evaluation Acc@1 44.370 Acc@5 92.380\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.590 Acc@1 41.968 Acc@5 89.006\n",
      "........................................\n",
      "Float Epoch 3: evaluation Acc@1 49.050 Acc@5 92.990\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.499 Acc@1 45.728 Acc@5 90.612\n",
      "........................................\n",
      "Float Epoch 4: evaluation Acc@1 53.110 Acc@5 94.200\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.410 Acc@1 49.342 Acc@5 92.054\n",
      "........................................\n",
      "Float Epoch 5: evaluation Acc@1 51.870 Acc@5 94.070\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.341 Acc@1 52.032 Acc@5 92.766\n",
      "........................................\n",
      "Float Epoch 6: evaluation Acc@1 58.490 Acc@5 95.540\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.269 Acc@1 54.996 Acc@5 93.532\n",
      "........................................\n",
      "Float Epoch 7: evaluation Acc@1 58.990 Acc@5 95.790\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.209 Acc@1 57.056 Acc@5 94.220\n",
      "........................................\n",
      "Float Epoch 8: evaluation Acc@1 62.510 Acc@5 95.520\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.160 Acc@1 58.780 Acc@5 94.850\n",
      "........................................\n",
      "Float Epoch 9: evaluation Acc@1 64.540 Acc@5 96.760\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.107 Acc@1 61.176 Acc@5 95.360\n",
      "........................................\n",
      "Float Epoch 10: evaluation Acc@1 66.620 Acc@5 96.730\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.068 Acc@1 62.632 Acc@5 95.686\n",
      "........................................\n",
      "Float Epoch 11: evaluation Acc@1 67.840 Acc@5 97.270\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 1.024 Acc@1 64.314 Acc@5 96.082\n",
      "........................................\n",
      "Float Epoch 12: evaluation Acc@1 68.030 Acc@5 97.470\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.990 Acc@1 65.382 Acc@5 96.398\n",
      "........................................\n",
      "Float Epoch 13: evaluation Acc@1 68.250 Acc@5 97.250\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.960 Acc@1 66.444 Acc@5 96.632\n",
      "........................................\n",
      "Float Epoch 14: evaluation Acc@1 69.010 Acc@5 97.520\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.933 Acc@1 67.430 Acc@5 96.776\n",
      "........................................\n",
      "Float Epoch 15: evaluation Acc@1 71.570 Acc@5 97.700\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.908 Acc@1 68.390 Acc@5 97.054\n",
      "........................................\n",
      "Float Epoch 16: evaluation Acc@1 72.590 Acc@5 97.880\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.883 Acc@1 69.462 Acc@5 97.228\n",
      "........................................\n",
      "Float Epoch 17: evaluation Acc@1 73.240 Acc@5 98.140\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.858 Acc@1 70.334 Acc@5 97.344\n",
      "........................................\n",
      "Float Epoch 18: evaluation Acc@1 73.790 Acc@5 98.210\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.846 Acc@1 70.760 Acc@5 97.442\n",
      "........................................\n",
      "Float Epoch 19: evaluation Acc@1 73.080 Acc@5 98.330\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.822 Acc@1 71.478 Acc@5 97.598\n",
      "........................................\n",
      "Float Epoch 20: evaluation Acc@1 75.550 Acc@5 98.200\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.806 Acc@1 72.036 Acc@5 97.704\n",
      "........................................\n",
      "Float Epoch 21: evaluation Acc@1 76.050 Acc@5 98.430\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.797 Acc@1 72.646 Acc@5 97.636\n",
      "........................................\n",
      "Float Epoch 22: evaluation Acc@1 75.890 Acc@5 98.340\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.778 Acc@1 73.274 Acc@5 97.766\n",
      "........................................\n",
      "Float Epoch 23: evaluation Acc@1 77.110 Acc@5 98.470\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.770 Acc@1 73.400 Acc@5 97.830\n",
      "........................................\n",
      "Float Epoch 24: evaluation Acc@1 76.630 Acc@5 98.430\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.756 Acc@1 73.812 Acc@5 97.968\n",
      "........................................\n",
      "Float Epoch 25: evaluation Acc@1 76.980 Acc@5 98.610\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.746 Acc@1 74.288 Acc@5 97.898\n",
      "........................................\n",
      "Float Epoch 26: evaluation Acc@1 77.960 Acc@5 98.630\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.734 Acc@1 74.766 Acc@5 98.084\n",
      "........................................\n",
      "Float Epoch 27: evaluation Acc@1 75.660 Acc@5 98.570\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.726 Acc@1 75.078 Acc@5 98.018\n",
      "........................................\n",
      "Float Epoch 28: evaluation Acc@1 78.440 Acc@5 98.640\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.717 Acc@1 75.390 Acc@5 98.180\n",
      "........................................\n",
      "Float Epoch 29: evaluation Acc@1 79.410 Acc@5 98.740\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# 用户可根据需要修改以下参数\n",
    "# 1. 模型 ckpt 和编译产出物的保存路径\n",
    "model_path = \"model/mobilenetv2\"\n",
    "# 2. 数据集下载和保存的路径\n",
    "data_path = \"data\"\n",
    "# 3. 训练时使用的 batch_size\n",
    "train_batch_size = 256\n",
    "# 4. 预测时使用的 batch_size\n",
    "eval_batch_size = 256\n",
    "# 5. 训练的 epoch 数\n",
    "epoch_num = 30\n",
    "# 6. 模型保存和执行计算使用的 device\n",
    "device = (\n",
    "    torch.device(\"cuda\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "######################################################################\n",
    "\n",
    "\n",
    "# 准备数据集，请注意 collate_fn 中对 rgb2centered_yuv 的使用\n",
    "def prepare_data_loaders(\n",
    "    data_path: str, train_batch_size: int, eval_batch_size: int\n",
    ") -> Tuple[data.DataLoader, data.DataLoader]:\n",
    "    normalize = transforms.Normalize(mean=0.0, std=128.0)\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        batched_img = torch.stack(\n",
    "            [\n",
    "                torch.from_numpy(np.array(example[0], np.uint8, copy=True))\n",
    "                for example in batch\n",
    "            ]\n",
    "        ).permute(0, 3, 1, 2)\n",
    "        batched_target = torch.tensor([example[1] for example in batch])\n",
    "\n",
    "        batched_img = rgb2centered_yuv(batched_img)\n",
    "        batched_img = normalize(batched_img.float())\n",
    "\n",
    "        return batched_img, batched_target\n",
    "\n",
    "    train_dataset = CIFAR10(\n",
    "        data_path,\n",
    "        True,\n",
    "        transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandAugment(),\n",
    "            ]\n",
    "        ),\n",
    "        download=True,\n",
    "    )\n",
    "\n",
    "    eval_dataset = CIFAR10(\n",
    "        data_path,\n",
    "        False,\n",
    "        download=True,\n",
    "    )\n",
    "\n",
    "    train_data_loader = data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=train_batch_size,\n",
    "        sampler=data.RandomSampler(train_dataset),\n",
    "        num_workers=8,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    eval_data_loader = data.DataLoader(\n",
    "        eval_dataset,\n",
    "        batch_size=eval_batch_size,\n",
    "        sampler=data.SequentialSampler(eval_dataset),\n",
    "        num_workers=8,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    return train_data_loader, eval_data_loader\n",
    "\n",
    "\n",
    "# 对浮点模型做必要的改造\n",
    "class FxQATReadyMobileNetV2(MobileNetV2):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 10,\n",
    "        width_mult: float = 1.0,\n",
    "        inverted_residual_setting: Optional[List[List[int]]] = None,\n",
    "        round_nearest: int = 8,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            num_classes, width_mult, inverted_residual_setting, round_nearest\n",
    "        )\n",
    "        self.quant = QuantStub(scale=1 / 128)\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.quant(x)\n",
    "        x = super().forward(x)\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# 浮点模型初始化\n",
    "float_model = FxQATReadyMobileNetV2()\n",
    "\n",
    "# 准备数据集\n",
    "train_data_loader, eval_data_loader = prepare_data_loaders(\n",
    "    data_path, train_batch_size, eval_batch_size\n",
    ")\n",
    "\n",
    "# 由于模型的最后一层和预训练模型不一致，需要进行浮点 finetune\n",
    "optimizer = torch.optim.Adam(\n",
    "    float_model.parameters(), lr=0.001, weight_decay=1e-3\n",
    ")\n",
    "best_acc = 0\n",
    "\n",
    "for nepoch in range(epoch_num):\n",
    "    float_model.train()\n",
    "    train_one_epoch(\n",
    "        float_model,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        optimizer,\n",
    "        None,\n",
    "        train_data_loader,\n",
    "        device,\n",
    "    )\n",
    "\n",
    "    # 浮点精度测试\n",
    "    float_model.eval()\n",
    "    top1, top5 = evaluate(float_model, eval_data_loader, device)\n",
    "\n",
    "    print(\n",
    "        \"Float Epoch {}: evaluation Acc@1 {:.3f} Acc@5 {:.3f}\".format(\n",
    "            nepoch, top1.avg, top5.avg\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if top1.avg > best_acc:\n",
    "        best_acc = top1.avg\n",
    "        # 保存最佳浮点模型参数\n",
    "        torch.save(\n",
    "            float_model.state_dict(),\n",
    "            os.path.join(model_path, \"float-checkpoint.ckpt\"),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "\n",
    "模型改造完成并完成浮点训练后，便可进行 Calibration。此过程通过在模型中插入 Observer 的方式，在 forward 过程中统计各处的数据分布情况，从而计算出合理的量化参数：\n",
    "\n",
    "- 对于部分模型，仅通过 Calibration 便可使精度达到要求，不必进行比较耗时的量化感知训练。\n",
    "- 即使模型经过量化校准后无法满足精度要求，此过程也可降低后续量化感知训练的难度，缩短训练时间，提升最终的训练精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "....................................................................................................................................................................................................\n",
      "........................................\n",
      "Calibration: evaluation Acc@1 79.270 Acc@5 98.710\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# 用户可根据需要修改以下参数\n",
    "# 1. Calibration 时使用的 batch_size\n",
    "calib_batch_size = 256\n",
    "# 2. Validation 时使用的 batch_size\n",
    "eval_batch_size = 256\n",
    "# 3. Calibration 使用的数据量，配置为 inf 以使用全部数据\n",
    "num_examples = float(\"inf\")\n",
    "# 4. 目标硬件平台的代号\n",
    "march = March.BAYES\n",
    "######################################################################\n",
    "\n",
    "# 在进行模型转化前，必须设置好模型将要执行的硬件平台\n",
    "set_march(march)\n",
    "\n",
    "\n",
    "# 将模型转化为 Calibration 状态，以统计各处数据的数值分布特征\n",
    "calib_model = prepare_qat_fx(\n",
    "    # 输出模型会共享输入模型的 attributes，为不影响 float_model 的后续使用,\n",
    "    # 此处进行了 deepcopy\n",
    "    copy.deepcopy(float_model),\n",
    "    {\n",
    "        \"\": default_calib_8bit_fake_quant_qconfig,\n",
    "        \"module_name\": {\n",
    "            # 在模型的输出层为 Conv 或 Linear 时，可以使用 out_qconfig\n",
    "            # 配置为高精度输出\n",
    "            \"classifier\": default_calib_out_8bit_fake_quant_qconfig,\n",
    "        },\n",
    "    },\n",
    ").to(\n",
    "    device\n",
    ")  # prepare_qat_fx 接口不保证输出模型的 device 和输入模型完全一致\n",
    "\n",
    "# 准备数据集\n",
    "calib_data_loader, eval_data_loader = prepare_data_loaders(\n",
    "    data_path, calib_batch_size, eval_batch_size\n",
    ")\n",
    "\n",
    "# 执行 Calibration 过程（不需要 backward）\n",
    "# 注意此处对模型状态的控制，模型需要处于 eval 状态以使 Bn 的行为符合要求\n",
    "calib_model.eval()\n",
    "set_fake_quantize(calib_model, FakeQuantState.CALIBRATION)\n",
    "with torch.no_grad():\n",
    "    cnt = 0\n",
    "    for image, target in calib_data_loader:\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        calib_model(image)\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        cnt += image.size(0)\n",
    "        if cnt >= num_examples:\n",
    "            break\n",
    "    print()\n",
    "\n",
    "# 测试伪量化精度\n",
    "# 注意此处对模型状态的控制\n",
    "calib_model.eval()\n",
    "set_fake_quantize(calib_model, FakeQuantState.VALIDATION)\n",
    "\n",
    "top1, top5 = evaluate(\n",
    "    calib_model,\n",
    "    eval_data_loader,\n",
    "    device,\n",
    ")\n",
    "print(\n",
    "    \"Calibration: evaluation Acc@1 {:.3f} Acc@5 {:.3f}\".format(\n",
    "        top1.avg, top5.avg\n",
    "    )\n",
    ")\n",
    "\n",
    "# 保存 Calibration 模型参数\n",
    "torch.save(\n",
    "    calib_model.state_dict(),\n",
    "    os.path.join(model_path, \"calib-checkpoint.ckpt\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型经过 Calibration 后的量化精度若已满足要求，便可直接进行[转定点模型](#转定点模型)的步骤，否则需要进行[量化训练](#量化训练)进一步提升精度。\n",
    "\n",
    "## 量化训练\n",
    "\n",
    "量化训练通过在模型中插入伪量化节点的方式，在训练过程中使模型感知到量化带来的影响，在这种情况下对模型参数进行微调，以提升量化后的精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.765 Acc@1 73.468 Acc@5 97.952\n",
      "........................................\n",
      "QAT Epoch 0: evaluation Acc@1 78.070 Acc@5 98.280\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.740 Acc@1 74.382 Acc@5 98.018\n",
      "........................................\n",
      "QAT Epoch 1: evaluation Acc@1 77.800 Acc@5 98.560\n",
      "....................................................................................................................................................................................................\n",
      "Full cifar-10 train set: Loss 0.718 Acc@1 75.272 Acc@5 98.108\n",
      "........................................\n",
      "QAT Epoch 2: evaluation Acc@1 78.260 Acc@5 98.570\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# 用户可根据需要修改以下参数\n",
    "# 1. 训练时使用的 batch_size\n",
    "train_batch_size = 256\n",
    "# 2. Validation 时使用的 batch_size\n",
    "eval_batch_size = 256\n",
    "# 3. 训练的 epoch 数\n",
    "epoch_num = 3\n",
    "######################################################################\n",
    "\n",
    "# 准备数据集\n",
    "train_data_loader, eval_data_loader = prepare_data_loaders(\n",
    "    data_path, train_batch_size, eval_batch_size\n",
    ")\n",
    "\n",
    "# 将模型转为 QAT 状态\n",
    "qat_model = prepare_qat_fx(\n",
    "    copy.deepcopy(float_model),\n",
    "    {\n",
    "        \"\": default_qat_8bit_fake_quant_qconfig,\n",
    "        \"module_name\": {\n",
    "            \"classifier\": default_qat_out_8bit_fake_quant_qconfig,\n",
    "        },\n",
    "    },\n",
    ").to(device)\n",
    "\n",
    "# 加载 Calibration 模型中的量化参数\n",
    "qat_model.load_state_dict(calib_model.state_dict())\n",
    "\n",
    "# 进行量化感知训练\n",
    "# 作为一个 filetune 过程，量化感知训练一般需要设定较小的学习率\n",
    "optimizer = torch.optim.Adam(\n",
    "    qat_model.parameters(), lr=1e-3, weight_decay=1e-4\n",
    ")\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "for nepoch in range(epoch_num):\n",
    "    # 注意此处对 QAT 模型 training 状态的控制方法\n",
    "    qat_model.train()\n",
    "    set_fake_quantize(qat_model, FakeQuantState.QAT)\n",
    "\n",
    "    train_one_epoch(\n",
    "        qat_model,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        optimizer,\n",
    "        None,\n",
    "        train_data_loader,\n",
    "        device,\n",
    "    )\n",
    "\n",
    "    # 注意此处对 QAT 模型 eval 状态的控制方法\n",
    "    qat_model.eval()\n",
    "    set_fake_quantize(qat_model, FakeQuantState.VALIDATION)\n",
    "\n",
    "    top1, top5 = evaluate(\n",
    "        qat_model,\n",
    "        eval_data_loader,\n",
    "        device,\n",
    "    )\n",
    "    print(\n",
    "        \"QAT Epoch {}: evaluation Acc@1 {:.3f} Acc@5 {:.3f}\".format(\n",
    "            nepoch, top1.avg, top5.avg\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if top1.avg > best_acc:\n",
    "        best_acc = top1.avg\n",
    "\n",
    "        torch.save(\n",
    "            qat_model.state_dict(),\n",
    "            os.path.join(model_path, \"qat-checkpoint.ckpt\"),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转定点模型\n",
    "\n",
    "伪量化精度达标后，便可将模型转为定点模型。一般认为定点模型的结果和编译后模型的结果是完全一致的。\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**注意**\n",
    "\n",
    "定点模型和伪量化模型之间无法做到完全数值一致，所以请以定点模型的精度为准。若定点精度不达标，需要继续进行量化训练。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................\n",
      "Quantized model: evaluation Acc@1 78.160 Acc@5 98.510\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# 用户可根据需要修改以下参数\n",
    "# 1. 使用哪个模型作为流程的输入，可以选择 calib_model 或 qat_model\n",
    "base_model = qat_model\n",
    "######################################################################\n",
    "\n",
    "# 将模型转为定点状态\n",
    "quantized_model = convert_fx(base_model).to(device)\n",
    "\n",
    "# 测试定点模型精度\n",
    "top1, top5 = evaluate(\n",
    "    quantized_model,\n",
    "    eval_data_loader,\n",
    "    device,\n",
    ")\n",
    "print(\n",
    "    \"Quantized model: evaluation Acc@1 {:.3f} Acc@5 {:.3f}\".format(\n",
    "        top1.avg, top5.avg\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型部署\n",
    "\n",
    "测试定点模型精度并确认符合要求后，便可以进行模型部署的相关流程，包括模型检查、编译、性能测试和可视化。\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**注意**\n",
    "\n",
    "- 也可以跳过 Calibration 和量化感知训练中的实际校准和训练过程，先直接进行模型检查，以保证模型中不存在无法编译的操作。\n",
    "- 由于编译器只支持 CPU，因此模型和数据必须放在 CPU 上。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model is supported!\n",
      "HBDK model check PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################\n",
    "# 用户可根据需要修改以下参数\n",
    "# 1. 编译时启用的优化等级，可选 0~3，等级越高编译出的模型上板执行速度越快，\n",
    "#    但编译过程会慢\n",
    "compile_opt = \"O1\"\n",
    "######################################################################\n",
    "\n",
    "# 这里的 example_input 也可以是随机生成的数据，但是推荐使用真实数据，以提高\n",
    "# 性能测试的准确性\n",
    "example_input = next(iter(eval_data_loader))[0]\n",
    "\n",
    "# 通过 trace 将模型序列化并生成计算图，注意模型和数据要放在 CPU 上\n",
    "script_model = torch.jit.trace(quantized_model.cpu(), example_input)\n",
    "torch.jit.save(script_model, os.path.join(model_path, \"int_model.pt\"))\n",
    "\n",
    "# 模型检查\n",
    "check_model(script_model, [example_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: launch 16 threads for optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ]   0%\r\n",
      "[-                                                 ]   1%\r\n",
      "[=-                                                ]   3%\r\n",
      "[==                                                ]   4%\r\n",
      "[===                                               ]   6%\r\n",
      "[===-                                              ]   7%\r\n",
      "[====-                                             ]   9%\r\n",
      "[=====                                             ]  10%\r\n",
      "[======                                            ]  12%\r\n",
      "[======-                                           ]  13%\r\n",
      "[=======-                                          ]  15%\r\n",
      "[========                                          ]  16%\r\n",
      "[=========                                         ]  18%\r\n",
      "[=========-                                        ]  19%\r\n",
      "[==========-                                       ]  21%\r\n",
      "[===========                                       ]  22%\r\n",
      "[============                                      ]  24%\r\n",
      "[============-                                     ]  25%\r\n",
      "[=============-                                    ]  27%\r\n",
      "[==============                                    ]  28%\r\n",
      "[===============                                   ]  30%\r\n",
      "[===============-                                  ]  31%\r\n",
      "[================-                                 ]  33%\r\n",
      "[=================                                 ]  34%\r\n",
      "[==================                                ]  36%\r\n",
      "[==================-                               ]  37%\r\n",
      "[===================-                              ]  39%\r\n",
      "[====================                              ]  40%\r\n",
      "[=====================                             ]  42%\r\n",
      "[=====================-                            ]  43%\r\n",
      "[======================-                           ]  45%\r\n",
      "[=======================                           ]  46%\r\n",
      "[========================                          ]  48%\r\n",
      "[=========================                         ]  50%\r\n",
      "[=========================-                        ]  51%\r\n",
      "[==========================-                       ]  53%\r\n",
      "[===========================                       ]  54%\r\n",
      "[============================                      ]  56%\r\n",
      "[============================-                     ]  57%\r\n",
      "[=============================-                    ]  59%\r\n",
      "[==============================                    ]  60%\r\n",
      "[===============================                   ]  62%\r\n",
      "[===============================-                  ]  63%\r\n",
      "[================================-                 ]  65%\r\n",
      "[=================================                 ]  66%\r\n",
      "[==================================                ]  68%\r\n",
      "[==================================-               ]  69%\r\n",
      "[===================================-              ]  71%\r\n",
      "[====================================              ]  72%\r\n",
      "[=====================================             ]  74%\r\n",
      "[=====================================-            ]  75%\r\n",
      "[======================================-           ]  77%\r\n",
      "[=======================================           ]  78%\r\n",
      "[========================================          ]  80%\r\n",
      "[========================================-         ]  81%\r\n",
      "[=========================================-        ]  83%\r\n",
      "[==========================================        ]  84%\r\n",
      "[===========================================       ]  86%\r\n",
      "[===========================================-      ]  87%\r\n",
      "[============================================-     ]  89%\r\n",
      "[=============================================     ]  90%\r\n",
      "[==============================================    ]  92%\r\n",
      "[==============================================-   ]  93%\r\n",
      "[===============================================-  ]  95%\r\n",
      "[================================================  ]  96%\r\n",
      "[================================================= ]  98%\r\n",
      "[==================================================] 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: arg0 can not be assigned to NCHW_NATIVE layout because it's input source is pyramid/resizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consumed time 16.8547\n",
      "HBDK model compilation SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型编译，生成的 hbm 文件即为可部署的模型\n",
    "compile_model(\n",
    "    script_model,\n",
    "    [example_input],\n",
    "    hbm=os.path.join(model_path, \"model.hbm\"),\n",
    "    input_source=\"pyramid\",\n",
    "    opt=compile_opt,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: launch 16 threads for optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ]   0%\r\n",
      "[-                                                 ]   1%\r\n",
      "[=-                                                ]   3%\r\n",
      "[==                                                ]   4%\r\n",
      "[===                                               ]   6%\r\n",
      "[===-                                              ]   7%\r\n",
      "[====-                                             ]   9%\r\n",
      "[=====                                             ]  10%\r\n",
      "[======                                            ]  12%\r\n",
      "[======-                                           ]  13%\r\n",
      "[=======-                                          ]  15%\r\n",
      "[========                                          ]  16%\r\n",
      "[=========                                         ]  18%\r\n",
      "[=========-                                        ]  19%\r\n",
      "[==========-                                       ]  21%\r\n",
      "[===========                                       ]  22%\r\n",
      "[============                                      ]  24%\r\n",
      "[============-                                     ]  25%\r\n",
      "[=============-                                    ]  27%\r\n",
      "[==============                                    ]  28%\r\n",
      "[===============                                   ]  30%\r\n",
      "[===============-                                  ]  31%\r\n",
      "[================-                                 ]  33%\r\n",
      "[=================                                 ]  34%\r\n",
      "[==================                                ]  36%\r\n",
      "[==================-                               ]  37%\r\n",
      "[===================-                              ]  39%\r\n",
      "[====================                              ]  40%\r\n",
      "[=====================                             ]  42%\r\n",
      "[=====================-                            ]  43%\r\n",
      "[======================-                           ]  45%\r\n",
      "[=======================                           ]  46%\r\n",
      "[========================                          ]  48%\r\n",
      "[=========================                         ]  50%\r\n",
      "[=========================-                        ]  51%\r\n",
      "[==========================-                       ]  53%\r\n",
      "[===========================                       ]  54%\r\n",
      "[============================                      ]  56%\r\n",
      "[============================-                     ]  57%\r\n",
      "[=============================-                    ]  59%\r\n",
      "[==============================                    ]  60%\r\n",
      "[===============================                   ]  62%\r\n",
      "[===============================-                  ]  63%\r\n",
      "[================================-                 ]  65%\r\n",
      "[=================================                 ]  66%\r\n",
      "[==================================                ]  68%\r\n",
      "[==================================-               ]  69%\r\n",
      "[===================================-              ]  71%\r\n",
      "[====================================              ]  72%\r\n",
      "[=====================================             ]  74%\r\n",
      "[=====================================-            ]  75%\r\n",
      "[======================================-           ]  77%\r\n",
      "[=======================================           ]  78%\r\n",
      "[========================================          ]  80%\r\n",
      "[========================================-         ]  81%\r\n",
      "[=========================================-        ]  83%\r\n",
      "[==========================================        ]  84%\r\n",
      "[===========================================       ]  86%\r\n",
      "[===========================================-      ]  87%\r\n",
      "[============================================-     ]  89%\r\n",
      "[=============================================     ]  90%\r\n",
      "[==============================================    ]  92%\r\n",
      "[==============================================-   ]  93%\r\n",
      "[===============================================-  ]  95%\r\n",
      "[================================================  ]  96%\r\n",
      "[================================================= ]  98%\r\n",
      "[==================================================] 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: arg0 can not be assigned to NCHW_NATIVE layout because it's input source is pyramid/resizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consumed time 17.6962\n",
      "HBDK model compilation SUCCESS\n",
      "  FPS=5868.15, latency = 43625.3 us   (see model/mobilenetv2/perf_out/FxQATReadyMobileNetV2.html)\n",
      "HBDK model compilation SUCCESS\n",
      "HBDK performance estimation SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary': {'BPU OPs per frame (effective)': 12249856,\n",
       "  'BPU OPs per frame (working)': 112174944,\n",
       "  'BPU OPs per run (effective)': 3135963136,\n",
       "  'BPU OPs per run (working)': 28716785664,\n",
       "  'BPU PE number': 1,\n",
       "  'BPU core number': 1,\n",
       "  'BPU march': 'BAYES',\n",
       "  'BPU utilization (effective)': 0.01,\n",
       "  'BPU utilization (optimal, conv only)': 0.004,\n",
       "  'BPU utilization (working)': 0.069,\n",
       "  'DDR bytes per frame': 1403592.0,\n",
       "  'DDR bytes per run': 359319552,\n",
       "  'DDR bytes per second': 8236493435,\n",
       "  'DDR megabytes per frame': 1.339,\n",
       "  'DDR megabytes per run': 342.674,\n",
       "  'DDR megabytes per second': 7854.9,\n",
       "  'FPS': 5868.15,\n",
       "  'FPS (optimal, conv only)': 1604982.13,\n",
       "  'HBDK version': '3.44.7',\n",
       "  'compiling options': '--march bayes -m /tmp/hbdktmp_l36nif9m.hbir -f hbir --O1 -o /tmp/hbdktmp_l36nif9m.hbm --jobs 16 -n FxQATReadyMobileNetV2 -i pyramid --input-name arg0 --output-layout NCHW --progressbar --debug',\n",
       "  'frame per run': 256,\n",
       "  'frame per second': 5868.15,\n",
       "  'input features': [['input name', 'input size'], ['arg0', '256x32x32x3']],\n",
       "  'interval computing unit utilization': [0.081,\n",
       "   0.113,\n",
       "   0.021,\n",
       "   0.001,\n",
       "   0.063,\n",
       "   0.004,\n",
       "   0.092,\n",
       "   0.019,\n",
       "   0.001,\n",
       "   0.016,\n",
       "   0.053,\n",
       "   0.021,\n",
       "   0.001,\n",
       "   0.093,\n",
       "   0.065,\n",
       "   0.078,\n",
       "   0.11,\n",
       "   0.108,\n",
       "   0.235,\n",
       "   0.078,\n",
       "   0.179,\n",
       "   0.246,\n",
       "   0.198,\n",
       "   0.154,\n",
       "   0.055,\n",
       "   0.131,\n",
       "   0.108,\n",
       "   0.048,\n",
       "   0.134,\n",
       "   0.145,\n",
       "   0.153,\n",
       "   0.044,\n",
       "   0.038,\n",
       "   0.056,\n",
       "   0.044,\n",
       "   0.009,\n",
       "   0.098,\n",
       "   0.155,\n",
       "   0.07,\n",
       "   0.075,\n",
       "   0.17,\n",
       "   0.233,\n",
       "   0.046,\n",
       "   0.11],\n",
       "  'interval computing units utilization': [0.081,\n",
       "   0.113,\n",
       "   0.021,\n",
       "   0.001,\n",
       "   0.063,\n",
       "   0.004,\n",
       "   0.092,\n",
       "   0.019,\n",
       "   0.001,\n",
       "   0.016,\n",
       "   0.053,\n",
       "   0.021,\n",
       "   0.001,\n",
       "   0.093,\n",
       "   0.065,\n",
       "   0.078,\n",
       "   0.11,\n",
       "   0.108,\n",
       "   0.235,\n",
       "   0.078,\n",
       "   0.179,\n",
       "   0.246,\n",
       "   0.198,\n",
       "   0.154,\n",
       "   0.055,\n",
       "   0.131,\n",
       "   0.108,\n",
       "   0.048,\n",
       "   0.134,\n",
       "   0.145,\n",
       "   0.153,\n",
       "   0.044,\n",
       "   0.038,\n",
       "   0.056,\n",
       "   0.044,\n",
       "   0.009,\n",
       "   0.098,\n",
       "   0.155,\n",
       "   0.07,\n",
       "   0.075,\n",
       "   0.17,\n",
       "   0.233,\n",
       "   0.046,\n",
       "   0.11],\n",
       "  'interval convolution unit utilization': [0.037,\n",
       "   0.04,\n",
       "   0.021,\n",
       "   0.0,\n",
       "   0.016,\n",
       "   0.017,\n",
       "   0.025,\n",
       "   0.032,\n",
       "   0.008,\n",
       "   0.0,\n",
       "   0.019,\n",
       "   0.019,\n",
       "   0.0,\n",
       "   0.023,\n",
       "   0.037,\n",
       "   0.053,\n",
       "   0.082,\n",
       "   0.075,\n",
       "   0.139,\n",
       "   0.146,\n",
       "   0.129,\n",
       "   0.187,\n",
       "   0.196,\n",
       "   0.176,\n",
       "   0.104,\n",
       "   0.072,\n",
       "   0.071,\n",
       "   0.05,\n",
       "   0.057,\n",
       "   0.07,\n",
       "   0.113,\n",
       "   0.099,\n",
       "   0.034,\n",
       "   0.037,\n",
       "   0.047,\n",
       "   0.026,\n",
       "   0.029,\n",
       "   0.102,\n",
       "   0.113,\n",
       "   0.073,\n",
       "   0.123,\n",
       "   0.202,\n",
       "   0.117,\n",
       "   0.002],\n",
       "  'interval loading bandwidth (megabytes/s)': [798,\n",
       "   2190,\n",
       "   3291,\n",
       "   3001,\n",
       "   4527,\n",
       "   6356,\n",
       "   5985,\n",
       "   4096,\n",
       "   3098,\n",
       "   5315,\n",
       "   5907,\n",
       "   3763,\n",
       "   2887,\n",
       "   4891,\n",
       "   6121,\n",
       "   4107,\n",
       "   2900,\n",
       "   1686,\n",
       "   3146,\n",
       "   4372,\n",
       "   2714,\n",
       "   2178,\n",
       "   2141,\n",
       "   2458,\n",
       "   3563,\n",
       "   4547,\n",
       "   3908,\n",
       "   4478,\n",
       "   3684,\n",
       "   3110,\n",
       "   3923,\n",
       "   3112,\n",
       "   4690,\n",
       "   6286,\n",
       "   3629,\n",
       "   3864,\n",
       "   6731,\n",
       "   3723,\n",
       "   3090,\n",
       "   5826,\n",
       "   4969,\n",
       "   1941,\n",
       "   2990,\n",
       "   5019],\n",
       "  'interval number': 44,\n",
       "  'interval storing bandwidth (megabytes/s)': [4000,\n",
       "   3368,\n",
       "   4334,\n",
       "   6936,\n",
       "   5824,\n",
       "   3695,\n",
       "   2524,\n",
       "   3720,\n",
       "   6066,\n",
       "   4863,\n",
       "   2938,\n",
       "   3924,\n",
       "   6061,\n",
       "   4752,\n",
       "   2250,\n",
       "   2238,\n",
       "   3000,\n",
       "   4500,\n",
       "   3000,\n",
       "   1500,\n",
       "   3000,\n",
       "   3000,\n",
       "   3000,\n",
       "   3114,\n",
       "   4395,\n",
       "   3602,\n",
       "   3399,\n",
       "   3782,\n",
       "   3454,\n",
       "   4500,\n",
       "   3765,\n",
       "   4682,\n",
       "   5984,\n",
       "   3494,\n",
       "   3847,\n",
       "   6822,\n",
       "   3652,\n",
       "   3011,\n",
       "   5787,\n",
       "   4488,\n",
       "   2962,\n",
       "   4252,\n",
       "   3749,\n",
       "   752],\n",
       "  'interval time (ms)': 1.0,\n",
       "  'latency (ms)': 43.63,\n",
       "  'latency (ms) by segments': [43.625],\n",
       "  'latency (us)': 43625.3,\n",
       "  'layer details': [['layer',\n",
       "    'original ops',\n",
       "    'original cost',\n",
       "    'computing cost (no DDR)',\n",
       "    'layer util (no DDR)',\n",
       "    'load/store cost',\n",
       "    'layer util (with DDR)',\n",
       "    'active period of time'],\n",
       "   ['_features_0_0_hz_conv2d',\n",
       "    '113,246,208',\n",
       "    '6 us (1.3% of model)',\n",
       "    '29 us (0% of model)',\n",
       "    '19.6%',\n",
       "    '267 us (0.6% of model)',\n",
       "    '1.9%',\n",
       "    '0 ~ 332 us (332)'],\n",
       "   ['_features_1_conv_0_0_hz_conv2d',\n",
       "    '37,748,736',\n",
       "    '2 us (0.4% of model)',\n",
       "    '42 us (0% of model)',\n",
       "    '4.5%',\n",
       "    '1156 us (2.6% of model)',\n",
       "    '0.1%',\n",
       "    '282 ~ 1544 us (1262)'],\n",
       "   ['_features_1_conv_1_hz_conv2d',\n",
       "    '67,108,864',\n",
       "    '3 us (0.7% of model)',\n",
       "    '20 us (0% of model)',\n",
       "    '17.0%',\n",
       "    '1 us (0% of model)',\n",
       "    '16.2%',\n",
       "    '1544 ~ 1585 us (41)'],\n",
       "   ['_features_2_conv_0_0_hz_conv2d',\n",
       "    '201,326,592',\n",
       "    '10 us (2.3% of model)',\n",
       "    '44 us (0.1% of model)',\n",
       "    '23.0%',\n",
       "    '3132 us (7.1% of model)',\n",
       "    '0.3%',\n",
       "    '1545 ~ 4175 us (2630)'],\n",
       "   ['_features_2_conv_1_0_hz_conv2d',\n",
       "    '28,311,552',\n",
       "    '1 us (0.3% of model)',\n",
       "    '54 us (0.1% of model)',\n",
       "    '2.6%',\n",
       "    '3132 us (7.1% of model)',\n",
       "    '0%',\n",
       "    '2644 ~ 6735 us (4091)'],\n",
       "   ['_features_2_conv_2_hz_conv2d',\n",
       "    '75,497,472',\n",
       "    '4 us (0.8% of model)',\n",
       "    '23 us (0% of model)',\n",
       "    '16.3%',\n",
       "    '1 us (0% of model)',\n",
       "    '15.5%',\n",
       "    '6735 ~ 6783 us (48)'],\n",
       "   ['_features_3_conv_0_0_hz_conv2d',\n",
       "    '113,246,208',\n",
       "    '6 us (1.3% of model)',\n",
       "    '24 us (0% of model)',\n",
       "    '23.9%',\n",
       "    '638 us (1.4% of model)',\n",
       "    '0.8%',\n",
       "    '6736 ~ 7443 us (707)'],\n",
       "   ['_features_3_conv_1_0_hz_conv2d',\n",
       "    '42,467,328',\n",
       "    '2 us (0.4% of model)',\n",
       "    '33 us (0% of model)',\n",
       "    '6.5%',\n",
       "    '3592 us (8.2% of model)',\n",
       "    '0%',\n",
       "    '6739 ~ 10117 us (3378)'],\n",
       "   ['_features_3_generated_add_0_hz_conv2d',\n",
       "    '113,246,208',\n",
       "    '6 us (1.3% of model)',\n",
       "    '14 us (0% of model)',\n",
       "    '39.9%',\n",
       "    '637 us (1.4% of model)',\n",
       "    '0.8%',\n",
       "    '6783 ~ 10782 us (3999)'],\n",
       "   ['_features_4_conv_0_0_hz_conv2d',\n",
       "    '113,246,208',\n",
       "    '6 us (1.3% of model)',\n",
       "    '45 us (0.1% of model)',\n",
       "    '12.6%',\n",
       "    '2433 us (5.5% of model)',\n",
       "    '0.2%',\n",
       "    '9071 ~ 12836 us (3765)'],\n",
       "   ['_features_4_conv_1_0_hz_conv2d',\n",
       "    '10,616,832',\n",
       "    '1 us (0.1% of model)',\n",
       "    '63 us (0.1% of model)',\n",
       "    '0.8%',\n",
       "    '2432 us (5.5% of model)',\n",
       "    '0%',\n",
       "    '9959 ~ 14951 us (4992)'],\n",
       "   ['_features_4_conv_2_hz_conv2d',\n",
       "    '37,748,736',\n",
       "    '2 us (0.4% of model)',\n",
       "    '21 us (0% of model)',\n",
       "    '9.1%',\n",
       "    '1 us (0% of model)',\n",
       "    '8.6%',\n",
       "    '14618 ~ 14993 us (375)'],\n",
       "   ['_features_5_conv_0_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '40 us (0% of model)',\n",
       "    '6.3%',\n",
       "    '3 us (0% of model)',\n",
       "    '5.9%',\n",
       "    '14092 ~ 15033 us (941)'],\n",
       "   ['_features_5_conv_1_0_hz_conv2d',\n",
       "    '14,155,776',\n",
       "    '1 us (0.1% of model)',\n",
       "    '45 us (0.1% of model)',\n",
       "    '1.6%',\n",
       "    '463 us (1.0% of model)',\n",
       "    '0.1%',\n",
       "    '9959 ~ 15539 us (5580)'],\n",
       "   ['_features_5_generated_add_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '23 us (0% of model)',\n",
       "    '10.9%',\n",
       "    '462 us (1.0% of model)',\n",
       "    '0.5%',\n",
       "    '9960 ~ 16047 us (6087)'],\n",
       "   ['_features_6_conv_0_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '40 us (0% of model)',\n",
       "    '6.3%',\n",
       "    '3 us (0% of model)',\n",
       "    '5.9%',\n",
       "    '6784 ~ 16087 us (9303)'],\n",
       "   ['_features_6_conv_1_0_hz_conv2d',\n",
       "    '14,155,776',\n",
       "    '1 us (0.1% of model)',\n",
       "    '23 us (0% of model)',\n",
       "    '3.0%',\n",
       "    '463 us (1.0% of model)',\n",
       "    '0.1%',\n",
       "    '6787 ~ 16572 us (9785)'],\n",
       "   ['_features_6_generated_add_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '23 us (0% of model)',\n",
       "    '10.9%',\n",
       "    '462 us (1.0% of model)',\n",
       "    '0.5%',\n",
       "    '15309 ~ 17080 us (1771)'],\n",
       "   ['_features_7_conv_0_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '61 us (0.1% of model)',\n",
       "    '4.2%',\n",
       "    '813 us (1.8% of model)',\n",
       "    '0.2%',\n",
       "    '16048 ~ 17951 us (1903)'],\n",
       "   ['_features_7_conv_1_0_hz_conv2d',\n",
       "    '3,538,944',\n",
       "    '<1 us',\n",
       "    '76 us (0.1% of model)',\n",
       "    '0.2%',\n",
       "    '812 us (1.8% of model)',\n",
       "    '0%',\n",
       "    '17141 ~ 18838 us (1697)'],\n",
       "   ['_features_7_conv_2_hz_conv2d',\n",
       "    '25,165,824',\n",
       "    '1 us (0.2% of model)',\n",
       "    '47 us (0.1% of model)',\n",
       "    '2.7%',\n",
       "    '3 us (0% of model)',\n",
       "    '2.5%',\n",
       "    '18817 ~ 18887 us (70)'],\n",
       "   ['_features_8_conv_0_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '76 us (0.1% of model)',\n",
       "    '3.3%',\n",
       "    '5 us (0% of model)',\n",
       "    '3.1%',\n",
       "    '18840 ~ 18963 us (123)'],\n",
       "   ['_features_8_conv_1_0_hz_conv2d',\n",
       "    '7,077,888',\n",
       "    '<1 us',\n",
       "    '75 us (0.1% of model)',\n",
       "    '0.4%',\n",
       "    '463 us (1.0% of model)',\n",
       "    '0%',\n",
       "    '18224 ~ 19500 us (1276)'],\n",
       "   ['_features_8_generated_add_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '67 us (0.1% of model)',\n",
       "    '3.7%',\n",
       "    '465 us (1.0% of model)',\n",
       "    '0.4%',\n",
       "    '18887 ~ 20028 us (1141)'],\n",
       "   ['_features_9_conv_0_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '76 us (0.1% of model)',\n",
       "    '3.3%',\n",
       "    '5 us (0% of model)',\n",
       "    '3.1%',\n",
       "    '19269 ~ 20104 us (835)'],\n",
       "   ['_features_9_conv_1_0_hz_conv2d',\n",
       "    '7,077,888',\n",
       "    '<1 us',\n",
       "    '75 us (0.1% of model)',\n",
       "    '0.4%',\n",
       "    '463 us (1.0% of model)',\n",
       "    '0%',\n",
       "    '19274 ~ 20640 us (1366)'],\n",
       "   ['_features_9_generated_add_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '67 us (0.1% of model)',\n",
       "    '3.7%',\n",
       "    '465 us (1.0% of model)',\n",
       "    '0.4%',\n",
       "    '20030 ~ 21169 us (1139)'],\n",
       "   ['_features_10_conv_0_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '76 us (0.1% of model)',\n",
       "    '3.3%',\n",
       "    '5 us (0% of model)',\n",
       "    '3.1%',\n",
       "    '20105 ~ 21245 us (1140)'],\n",
       "   ['_features_10_conv_1_0_hz_conv2d',\n",
       "    '7,077,888',\n",
       "    '<1 us',\n",
       "    '51 us (0.1% of model)',\n",
       "    '0.7%',\n",
       "    '463 us (1.0% of model)',\n",
       "    '0%',\n",
       "    '18226 ~ 21809 us (3583)'],\n",
       "   ['_features_10_generated_add_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '47 us (0.1% of model)',\n",
       "    '5.4%',\n",
       "    '465 us (1.0% of model)',\n",
       "    '0.4%',\n",
       "    '21103 ~ 22317 us (1214)'],\n",
       "   ['_features_11_conv_0_0_hz_conv2d',\n",
       "    '50,331,648',\n",
       "    '3 us (0.5% of model)',\n",
       "    '76 us (0.1% of model)',\n",
       "    '3.3%',\n",
       "    '5 us (0% of model)',\n",
       "    '3.1%',\n",
       "    '21245 ~ 22393 us (1148)'],\n",
       "   ['_features_11_conv_1_0_hz_conv2d',\n",
       "    '7,077,888',\n",
       "    '<1 us',\n",
       "    '75 us (0.1% of model)',\n",
       "    '0.4%',\n",
       "    '463 us (1.0% of model)',\n",
       "    '0%',\n",
       "    '20411 ~ 22929 us (2518)'],\n",
       "   ['_features_11_conv_2_hz_conv2d',\n",
       "    '75,497,472',\n",
       "    '4 us (0.8% of model)',\n",
       "    '110 us (0.2% of model)',\n",
       "    '3.4%',\n",
       "    '467 us (1.0% of model)',\n",
       "    '0.6%',\n",
       "    '22271 ~ 23500 us (1229)'],\n",
       "   ['_features_12_conv_0_0_hz_conv2d',\n",
       "    '113,246,208',\n",
       "    '6 us (1.3% of model)',\n",
       "    '43 us (0% of model)',\n",
       "    '13.2%',\n",
       "    '644 us (1.4% of model)',\n",
       "    '0.8%',\n",
       "    '22277 ~ 24179 us (1902)'],\n",
       "   ['_features_12_conv_1_0_hz_conv2d',\n",
       "    '10,616,832',\n",
       "    '1 us (0.1% of model)',\n",
       "    '55 us (0.1% of model)',\n",
       "    '0.9%',\n",
       "    '1274 us (2.9% of model)',\n",
       "    '0%',\n",
       "    '21658 ~ 25030 us (3372)'],\n",
       "   ['_features_12_generated_add_0_hz_conv2d',\n",
       "    '113,246,208',\n",
       "    '6 us (1.3% of model)',\n",
       "    '45 us (0.1% of model)',\n",
       "    '12.7%',\n",
       "    '643 us (1.4% of model)',\n",
       "    '0.8%',\n",
       "    '22400 ~ 25710 us (3310)'],\n",
       "   ['_features_13_conv_0_0_hz_conv2d',\n",
       "    '113,246,208',\n",
       "    '6 us (1.3% of model)',\n",
       "    '43 us (0% of model)',\n",
       "    '13.2%',\n",
       "    '644 us (1.4% of model)',\n",
       "    '0.8%',\n",
       "    '24871 ~ 26439 us (1568)'],\n",
       "   ['_features_13_conv_1_0_hz_conv2d',\n",
       "    '10,616,832',\n",
       "    '1 us (0.1% of model)',\n",
       "    '55 us (0.1% of model)',\n",
       "    '0.9%',\n",
       "    '1274 us (2.9% of model)',\n",
       "    '0%',\n",
       "    '22699 ~ 27345 us (4646)'],\n",
       "   ['_features_13_generated_add_0_hz_conv2d',\n",
       "    '113,246,208',\n",
       "    '6 us (1.3% of model)',\n",
       "    '45 us (0.1% of model)',\n",
       "    '12.7%',\n",
       "    '643 us (1.4% of model)',\n",
       "    '0.8%',\n",
       "    '25351 ~ 28026 us (2675)'],\n",
       "   ['_features_14_conv_0_0_hz_conv2d',\n",
       "    '113,246,208',\n",
       "    '6 us (1.3% of model)',\n",
       "    '67 us (0.1% of model)',\n",
       "    '8.6%',\n",
       "    '644 us (1.4% of model)',\n",
       "    '0.8%',\n",
       "    '25717 ~ 28799 us (3082)'],\n",
       "   ['_features_14_conv_1_0_hz_conv2d',\n",
       "    '2,654,208',\n",
       "    '<1 us',\n",
       "    '72 us (0.1% of model)',\n",
       "    '0.1%',\n",
       "    '1274 us (2.9% of model)',\n",
       "    '0%',\n",
       "    '24874 ~ 29813 us (4939)'],\n",
       "   ['_features_14_conv_2_hz_conv2d',\n",
       "    '47,185,920',\n",
       "    '2 us (0.5% of model)',\n",
       "    '108 us (0.2% of model)',\n",
       "    '2.2%',\n",
       "    '647 us (1.4% of model)',\n",
       "    '0.3%',\n",
       "    '27187 ~ 30556 us (3369)'],\n",
       "   ['_features_15_conv_0_0_hz_conv2d',\n",
       "    '78,643,200',\n",
       "    '4 us (0.9% of model)',\n",
       "    '47 us (0.1% of model)',\n",
       "    '8.5%',\n",
       "    '1004 us (2.3% of model)',\n",
       "    '0.3%',\n",
       "    '28481 ~ 31589 us (3108)'],\n",
       "   ['_features_15_conv_1_0_hz_conv2d',\n",
       "    '4,423,680',\n",
       "    '<1 us',\n",
       "    '51 us (0.1% of model)',\n",
       "    '0.4%',\n",
       "    '1973 us (4.5% of model)',\n",
       "    '0%',\n",
       "    '27184 ~ 32749 us (5565)'],\n",
       "   ['_features_15_generated_add_0_hz_conv2d',\n",
       "    '78,643,200',\n",
       "    '4 us (0.9% of model)',\n",
       "    '21 us (0% of model)',\n",
       "    '19.1%',\n",
       "    '1004 us (2.3% of model)',\n",
       "    '0.3%',\n",
       "    '29604 ~ 33777 us (4173)'],\n",
       "   ['_features_16_conv_0_0_hz_conv2d',\n",
       "    '78,643,200',\n",
       "    '4 us (0.9% of model)',\n",
       "    '47 us (0.1% of model)',\n",
       "    '8.5%',\n",
       "    '1004 us (2.3% of model)',\n",
       "    '0.3%',\n",
       "    '30567 ~ 34809 us (4242)'],\n",
       "   ['_features_16_conv_1_0_hz_conv2d',\n",
       "    '4,423,680',\n",
       "    '<1 us',\n",
       "    '51 us (0.1% of model)',\n",
       "    '0.4%',\n",
       "    '1973 us (4.5% of model)',\n",
       "    '0%',\n",
       "    '30131 ~ 35970 us (5839)'],\n",
       "   ['_features_16_generated_add_0_hz_conv2d',\n",
       "    '78,643,200',\n",
       "    '4 us (0.9% of model)',\n",
       "    '50 us (0.1% of model)',\n",
       "    '8.0%',\n",
       "    '1003 us (2.2% of model)',\n",
       "    '0.3%',\n",
       "    '33778 ~ 37054 us (3276)'],\n",
       "   ['_features_17_conv_0_0_hz_conv2d',\n",
       "    '78,643,200',\n",
       "    '4 us (0.9% of model)',\n",
       "    '154 us (0.3% of model)',\n",
       "    '2.5%',\n",
       "    '1004 us (2.3% of model)',\n",
       "    '0.3%',\n",
       "    '33796 ~ 38194 us (4398)'],\n",
       "   ['_features_17_conv_1_0_hz_conv2d',\n",
       "    '4,423,680',\n",
       "    '<1 us',\n",
       "    '73 us (0.1% of model)',\n",
       "    '0.3%',\n",
       "    '1973 us (4.5% of model)',\n",
       "    '0%',\n",
       "    '37055 ~ 39453 us (2398)'],\n",
       "   ['_features_17_conv_2_hz_conv2d',\n",
       "    '157,286,400',\n",
       "    '8 us (1.8% of model)',\n",
       "    '76 us (0.1% of model)',\n",
       "    '10.5%',\n",
       "    '1021 us (2.3% of model)',\n",
       "    '0.7%',\n",
       "    '37059 ~ 40514 us (3455)'],\n",
       "   ['_features_18_0_hz_conv2d',\n",
       "    '209,715,200',\n",
       "    '11 us (2.4% of model)',\n",
       "    '537 us (1.2% of model)',\n",
       "    '1.9%',\n",
       "    '2601 us (5.9% of model)',\n",
       "    '0.3%',\n",
       "    '37720 ~ 43604 us (5884)'],\n",
       "   ['_features_18_0_hz_conv2d_torch_native',\n",
       "    '0',\n",
       "    '273 us (63.1% of model)',\n",
       "    '11 us (0% of model)',\n",
       "    '2531.5%',\n",
       "    '0',\n",
       "    '2531.5%',\n",
       "    '43604 ~ 43615 us (11)'],\n",
       "   ['_classifier_1_hz_linear_torch_native',\n",
       "    '6,553,600',\n",
       "    '<1 us',\n",
       "    '5 us (0% of model)',\n",
       "    '7.3%',\n",
       "    '7 us (0% of model)',\n",
       "    '2.8%',\n",
       "    '43604 ~ 43625 us (21)']],\n",
       "  'loaded bytes per frame': 707232,\n",
       "  'loaded bytes per run': 181051392,\n",
       "  'model json CRC': '084ad85b',\n",
       "  'model json file': '/tmp/hbdktmp_l36nif9m.hbir',\n",
       "  'model name': 'FxQATReadyMobileNetV2',\n",
       "  'model param CRC': '00000000',\n",
       "  'multicore sync time (ms)': 0.0,\n",
       "  'run per second': 22.92,\n",
       "  'runtime version': '3.15.22.0',\n",
       "  'stored bytes per frame': 696360,\n",
       "  'stored bytes per run': 178268160,\n",
       "  'worst FPS': 5868.15}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型性能测试\n",
    "perf_model(\n",
    "    script_model,\n",
    "    [example_input],\n",
    "    out_dir=os.path.join(model_path, \"perf_out\"),\n",
    "    input_source=\"pyramid\",\n",
    "    opt=compile_opt,\n",
    "    layer_details=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: launch 1 threads for optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consumed time 2.85831\n",
      "HBDK model compilation SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# 模型可视化\n",
    "visualize_model(\n",
    "    script_model,\n",
    "    [example_input],\n",
    "    save_path=os.path.join(model_path, \"model.svg\"), show=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
